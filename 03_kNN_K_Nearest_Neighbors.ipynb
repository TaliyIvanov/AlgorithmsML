{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Шаг №1 - Инициализация класса"
      ],
      "metadata": {
        "id": "-s89s1HEs5mo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте класс с именем MyKNNClf. Данный класс при инициализации должен принимать только один параметр:\n",
        "\n",
        "k – кол-во ближайших соседей, которое будем рассматривать при определении класса.\n",
        "По-умолчанию: 3\n",
        "Все переданные (или дефолтные) параметры должны быть сохранены внутри экземпляра класса.\n",
        "\n",
        "При обращении к экземпляру класса (или при передачи его в функцию print) необходимо распечатать строку по следующему шаблону:\n",
        "\n",
        "MyKNNClf class: k=k"
      ],
      "metadata": {
        "id": "mc3i3IqHwSMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VY1o_Oc4spkN"
      },
      "outputs": [],
      "source": [
        "class MyKNNClf():\n",
        "  def __init__(self, k=3):\n",
        "    self.k = k\n",
        "\n",
        "  def __str__(self):\n",
        "    params = ', '.join(f'{key}={value}' for key, value in self.__dict__.items())\n",
        "    return f\"{__class__.__name__} class: {params}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Шаг №2 - Метод fit()"
      ],
      "metadata": {
        "id": "r63zUAxas8_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Доработайте класс MyKNNClf следующим образом:\n",
        "\n",
        "В инициализатор класса добавьте переменную train_size (не параметр, а именно переменную). В ней будет храниться размер обучающей выборки.\n",
        "Добавьте в класс метод fit. Данный метод должен делать следующее:\n",
        "На вход принимать две переменные:\n",
        "- X — все фичи в виде датафрейма пандаса.\n",
        "- y — целевая переменная в виде пандасовской серии.\n",
        "Сохранить X и y внутри модели.\n",
        "Записать в переменную train_size размер тренировочной выборки (X) в виде кортежа:\n",
        "(количество_строк, количество_столбцов)"
      ],
      "metadata": {
        "id": "htUWi2oawPN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "class MyKNNClf():\n",
        "  def __init__(self, k=3):\n",
        "    self.k = k\n",
        "    self.train_size = None # Переменная для хранения обучающей выборки\n",
        "    self.X = None # variable for features\n",
        "    self.y = None # varible for target label\n",
        "\n",
        "  def __str__(self):\n",
        "    params = ', '.join(f'{key}={value}' for key, value in self.__dict__.items())\n",
        "    return f\"{__class__.__name__} class: {params}\"\n",
        "\n",
        "  def fit(self, X:pd.DataFrame, y:pd.Series):\n",
        "    self.X = X # save features\n",
        "    self.y = y # save target label\n",
        "    self.train_size = X.shape # data size\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gQJCpBdqtDME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Шаг №3 - predict & predict proba"
      ],
      "metadata": {
        "id": "xtFBuJWrtDdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```markdown\n",
        "Добавьте в класс `MyKNNClf` методы `predict` и `predict_proba`. Данные методы должны делать следующее:\n",
        "\n",
        "### Метод `predict`\n",
        "\n",
        "- На вход принимает матрицу фичей в виде датафрейма `pandas`.\n",
        "- Для каждого объекта тестовой выборки последовательно выполняются следующие шаги:\n",
        "  1. Вычислить расстояние до каждого объекта из обучающей выборки.\n",
        "     - Сейчас расстояние будем вычислять по формуле Евклида. Для двух точек с тремя координатами (фичами) Евклидово расстояние считается так:\n",
        "\n",
        "     $$\n",
        "     D_{\\text{eucl}} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2 + (z_2 - z_1)^2}\n",
        "     $$\n",
        "\n",
        "     где:\n",
        "     - \\( x_1, y_1, z_1 \\) – координаты (или иные количественные свойства) первой точки,\n",
        "     - \\( x_2, y_2, z_2 \\) – координаты второй точки.\n",
        "  2. Отобрать \\( k \\) объектов обучающей выборки, расстояние до которых минимально.\n",
        "  3. Определить, какой класс наиболее часто встречается (мода) – это и будет классом целевого объекта.\n",
        "     - Если число объектов в каждом из классов одинаковое, возвращаем класс `1`.\n",
        "  \n",
        "- **Заметка:** Рассматриваем только задачу бинарной классификации (с классами `0` и `1`).\n",
        "- Вернуть вектор предсказаний.\n",
        "\n",
        "### Метод `predict_proba`\n",
        "\n",
        "- На вход принимает матрицу фичей в виде датафрейма `pandas`.\n",
        "- Для каждого объекта тестовой выборки последовательно выполняются следующие шаги:\n",
        "  1. Вычислить Евклидово расстояние до каждого объекта из обучающей выборки.\n",
        "  2. Отобрать \\( k \\) объектов обучающей выборки, расстояние до которых минимально.\n",
        "  3. Подсчитать вероятность для класса `1`.\n",
        "  \n",
        "- Вернуть список вероятностей.\n",
        "```"
      ],
      "metadata": {
        "id": "OXCWsyc31CHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class MyKNNClf():\n",
        "  def __init__(self, k=3):\n",
        "    self.k = k\n",
        "    self.train_size = None\n",
        "    self.X = None\n",
        "    self.y = None\n",
        "\n",
        "  def __str__(self):\n",
        "    params = ', '.join(f'{key}={value}' for key, value in __self__.__dict__.values())\n",
        "    return f'{__class__.__name__} class: {params}'\n",
        "\n",
        "  def fit(self, X:pd.DataFrame, y:pd.Series):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.train_size = X.shape\n",
        "\n",
        "\n",
        "  def predict(self, X_test:pd.DataFrame):\n",
        "    # вычисление расстояния от тестовых точек до всех в выборке X\n",
        "    distances = np.sqrt(((self.X.values - X_test.values[:, np.newaxis]) ** 2).sum(axis=2))\n",
        "    # индексы ближайших соседей\n",
        "    nearest_neighbors = np.argsort(distances, axis=1)[:, :self.k]\n",
        "    # классы ближайших соседей\n",
        "    nearest_labels = self.y.values[nearest_neighbors]\n",
        "    # мода\n",
        "    predicted_labels = []\n",
        "    for labels in nearest_labels:\n",
        "      # Используем np.bincount для подсчета количества каждого класса в k ближайших соседях\n",
        "      counts = np.bincount(labels, minlength=2) # Убедимся, что считаем для классов 0 и 1\n",
        "      # Если количество соседей для классов 0 и 1 одинаково, выбираем класс 1\n",
        "      if counts[0] == count[1]:\n",
        "        predicted_labels.append(1)\n",
        "      else:\n",
        "        predicted_labels.append(counts.argmax())\n",
        "    return np.array(predicted_labels)\n",
        "\n",
        "  def predict_proba(self, X_test:pd.DataFrame):\n",
        "    # вычисление расстояния от тестовых точек до всех в выборке X\n",
        "    distances = np.sqrt(((self.X.values - X_test.values[:, np.newaxis]) ** 2).sum(axis=2))\n",
        "    # индексы ближайших соседей\n",
        "    nearest_neighbors = np.argsort(distances, axis=1)[:, :self.k]\n",
        "    # классы ближайших соседей\n",
        "    nearest_labels = self.y.values[nearest_neighbors]\n",
        "    # вероятность класса 1\n",
        "    proba_class_1 = (nearest_labels == 1).mean(axis=1)\n",
        "    return proba_class_1"
      ],
      "metadata": {
        "id": "HkZK52DMtD1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Шаг №4 - Метрики"
      ],
      "metadata": {
        "id": "Fdhwy75EtLRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавьте в класс MyKNNClf параметр metric, который принимает одно из следующих значений:\n",
        "\n",
        "euclidean\n",
        "chebyshev\n",
        "manhattan\n",
        "cosine\n",
        "Значение по-умолчанию: euclidean\n",
        "\n",
        "При обучении и вычислении дистанции между точками должна использоваться соответствующая метрика. Как они рассчитываются описано в предыдущем разделе.\n",
        "\n",
        "Проверка\n",
        "\n",
        "Входные данные: названия метрик\n",
        "Выходные данные: возвращенные предсказания и предсказанные вероятности (их сумма)"
      ],
      "metadata": {
        "id": "fYHi2IpUE_wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyKNNClf():\n",
        "  # инициализация класса\n",
        "  def __init__(self, k=3, metric='euclidean'):\n",
        "    self.k = k\n",
        "    self.train_size = None\n",
        "    self.X = None\n",
        "    self.y = None\n",
        "    self.metric = metric\n",
        "\n",
        "  def __str__(self):\n",
        "    params = ', '.join(f'{key}={value}' for key, value in __self__.__dict__.values())\n",
        "    return f'{__class__.__name__} class: {params}'\n",
        "\n",
        "  def fit(self, X:pd.DataFrame, y:pd.Series):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.train_size = X.shape\n",
        "\n",
        "  def compute_metric(self, X_test:pd.DataFrame):\n",
        "    # вычисление расстояния в зависимости от заданных условий\n",
        "    if self.metric == 'euclidean':\n",
        "      distances = np.sqrt(((self.X.values - X_test.values[:, np.newaxis]) ** 2).sum(axis=2))\n",
        "      return distances\n",
        "    elif self.metric == 'chebyshev':\n",
        "      distances =  np.max(np.abs(self.X.values - X_test.values[:, np.newaxis]), axis=2)\n",
        "      return distances\n",
        "    elif self.metric == 'manhattan':\n",
        "      distances = np.abs(self.X.values - X_test.values[:, np.newaxis]).sum(axis=2)\n",
        "      return distances\n",
        "    elif self.metric == 'cosine':\n",
        "      X_norm = np.linalg.norm(self.X.values, axis=1)\n",
        "      X_test_norm = np.linalg.norm(X_test.values, axis=1)[:, np.newaxis]\n",
        "      cosine_similarity = np.dot(X_test.values, self.X.values.T) / (X_test_norm * X_norm)\n",
        "      distances = 1 - cosine_similarity\n",
        "      return distances\n",
        "\n",
        "\n",
        "  def predict(self, X_test:pd.DataFrame):\n",
        "    # вычисление расстояния от тестовых точек до всех в выборке X\n",
        "    distances = self.compute_metric(X_test)\n",
        "    # индексы ближайших соседей\n",
        "    nearest_neighbors = np.argsort(distances, axis=1)[:, :self.k]\n",
        "    # классы ближайших соседей по индексам\n",
        "    nearest_labels = self.y.values[nearest_neighbors]\n",
        "    # мода\n",
        "    predicted_labels = []\n",
        "    for labels in nearest_labels:\n",
        "      counts = np.bincount(labels, minlength=2) # Убедимся, что считаем для 0 и 1\n",
        "      # Если кол-во соседей для классов 0 и 1 одинаково, выбираем класс 1\n",
        "      if counts[0] == counts[1]:\n",
        "        predicted_labels.append(1)\n",
        "      else:\n",
        "        predicted_labels.append(counts.argmax())\n",
        "\n",
        "    return np.array(predicted_labels)\n",
        "\n",
        "  def predict_proba(self, X_test:pd.DataFrame):\n",
        "    # вычисление расстояния от тестовых точек до всех в выборке X\n",
        "    distances = self.compute_metric(X_test)\n",
        "    # индексы ближайших соседей\n",
        "    nearest_neighbors = np.argsort(distances, axis=1)[:, :self.k]\n",
        "    # классы ближайших соседей\n",
        "    nearest_labels = self.y.values[nearest_neighbors]\n",
        "    # вероятность класса 1\n",
        "    proba_class_1 = (nearest_labels == 1).mean(axis=1)\n",
        "    return proba_class_1"
      ],
      "metadata": {
        "id": "y-7jYbFjtLli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Шаг №5 - Взвешенный kNN"
      ],
      "metadata": {
        "id": "Sf9fyWp_tSFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавьте в класс MyKNNClf параметр weight, которые принимает одно из следующих значений:\n",
        "\n",
        "uniform\n",
        "rank\n",
        "distance\n",
        "Значение по-умолчанию: uniform\n",
        "\n",
        "Внесите следуюшие изменения в работу алгоритма:\n",
        "\n",
        "Если weight = uniform работаем как и раньше.\n",
        "Если weight = rank или distance, то:\n",
        "Метод predict должен вычислять и возвращать класс с наибольшим весом.\n",
        "Формулы по которым вычисляется вес класса приведены на [предыдущем шаге](https://stepik.org/lesson/329908/step/7?unit=313248).\n",
        "Метод predict_proba должен возвращать вес класса 1."
      ],
      "metadata": {
        "id": "a5Na5RY5VCPT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если я все правильно понял, то мне необходимо добавить в функции Predict и PredictProba по дополнительному способу расчета, тобишь я должен определять класс не только по моде, но и по другим метрикам)"
      ],
      "metadata": {
        "id": "dNXnDjk4fBAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class MyKNNClf():\n",
        "    def __init__(self, k=3, metric='euclidian', weight='uniform'):\n",
        "        self.k = k\n",
        "        self.train_size = None\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self.metric = metric\n",
        "        self.weight = weight\n",
        "\n",
        "    def __str__(self):\n",
        "        params = ', '.join(f\"{key}={value}\" for key, value in self.__dict__.items())\n",
        "        return f'{self.__class__.__name__} class: {params}'\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.train_size = X.shape\n",
        "\n",
        "    def compute_metric(self, X_test: pd.DataFrame):\n",
        "        # Вычисление расстояния в зависимости от метрики\n",
        "        if self.metric == 'euclidian':\n",
        "            distances = np.sqrt(((self.X.values - X_test.values[:, np.newaxis]) ** 2).sum(axis=2))\n",
        "        elif self.metric == 'chebyshev':\n",
        "            distances = np.max(np.abs(self.X.values - X_test.values[:, np.newaxis]), axis=2)\n",
        "        elif self.metric == 'manhattan':\n",
        "            distances = np.abs(self.X.values - X_test.values[:, np.newaxis]).sum(axis=2)\n",
        "        elif self.metric == 'cosine':\n",
        "            X_norm = np.linalg.norm(self.X.values, axis=1)\n",
        "            X_test_norm = np.linalg.norm(X_test.values, axis=1)[:, np.newaxis]\n",
        "            cosine_similarity = np.dot(X_test.values, self.X.values.T) / (X_test_norm * X_norm)\n",
        "            distances = 1 - cosine_similarity\n",
        "        return distances\n",
        "\n",
        "    def compute_labels(self, s: np.ndarray, distances: np.ndarray):\n",
        "        # s: метки соседей, distances: расстояния до соседей\n",
        "        predicted_labels = []\n",
        "        if self.weight == 'uniform':\n",
        "            for neighbors in s:\n",
        "                counts = np.bincount(neighbors, minlength=2)  # считаем для классов 0 и 1\n",
        "                if counts[0] == counts[1]:\n",
        "                    predicted_labels.append(1)  # при равенстве голосов выбираем класс 1\n",
        "                else:\n",
        "                    predicted_labels.append(counts.argmax())\n",
        "        else:\n",
        "            for neighbors, dist in zip(s, distances):\n",
        "                if self.weight == 'rank':\n",
        "                    weights = 1 / np.arange(1, len(neighbors) + 1)  # веса по рангу\n",
        "                elif self.weight == 'distance':\n",
        "                    weights = 1 / (dist)  # веса по расстоянию (добавляем малое число, чтобы избежать деления на ноль)\n",
        "\n",
        "                Q_0 = np.sum(weights[neighbors == 0])  # вес для класса 0\n",
        "                Q_1 = np.sum(weights[neighbors == 1])  # вес для класса 1\n",
        "                predicted_labels.append(0 if Q_0 > Q_1 else 1)  # выбираем класс с наибольшим весом\n",
        "        return np.array(predicted_labels)\n",
        "\n",
        "    def predict(self, X_test: pd.DataFrame):\n",
        "        # вычисление расстояний в зависимости от выбранной метрики\n",
        "        distances = self.compute_metric(X_test)\n",
        "        # индексы ближайших k соседей\n",
        "        nearest_neighbors = np.argsort(distances, axis=1)[:, :self.k]\n",
        "        # классы ближайших k соседей\n",
        "        nearest_labels = self.y.values[nearest_neighbors]\n",
        "        # предсказываем классы\n",
        "        predicted_labels = self.compute_labels(nearest_labels, distances[np.arange(len(distances))[:, None], nearest_neighbors])\n",
        "        return predicted_labels\n",
        "\n",
        "    def predict_proba(self, X_test: pd.DataFrame):\n",
        "        # вычисление расстояний от тестовых точек до всех в выборке X\n",
        "        distances = self.compute_metric(X_test)\n",
        "        # индексы ближайших k соседей\n",
        "        nearest_neighbors = np.argsort(distances, axis=1)[:, :self.k]\n",
        "        # классы ближайших соседей\n",
        "        nearest_labels = self.y.values[nearest_neighbors]\n",
        "\n",
        "        probas = []\n",
        "        for neighbors, dist in zip(nearest_labels, distances[np.arange(len(distances))[:, None], nearest_neighbors]):\n",
        "            if self.weight == 'uniform':\n",
        "                proba_class_1 = (neighbors == 1).mean()\n",
        "            else:\n",
        "                if self.weight == 'rank':\n",
        "                    weights = 1 / np.arange(1, len(neighbors) + 1)\n",
        "                elif self.weight == 'distance':\n",
        "                    weights = 1 / (dist)\n",
        "\n",
        "                Q_1 = np.sum(weights[neighbors == 1])\n",
        "                Q_total = np.sum(weights)\n",
        "                proba_class_1 = Q_1 / Q_total\n",
        "            probas.append(proba_class_1)\n",
        "\n",
        "        return np.array(probas)"
      ],
      "metadata": {
        "id": "qyDtCLVatSeX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}